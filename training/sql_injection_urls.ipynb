{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab135434",
   "metadata": {},
   "source": [
    "# SQL Injection URL Detection Model Training\n",
    "\n",
    "This notebook trains an Isolation Forest model to detect SQL injection attacks in HTTP URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca403614",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql_injection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_features\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Add project root to sys.path\n",
    "# This ensures we can import from src/ even if running from training/ subdirectory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "from src.features.sql_injection import extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416769e9",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "input_csv = '../data/csic_database.csv'\n",
    "df = pd.read_csv(input_csv, low_memory=False)\n",
    "print(f\"Loaded {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138ddc6",
   "metadata": {},
   "source": [
    "## Load and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and extract features using shared module\n",
    "input_csv = '../data/csic_database.csv'\n",
    "df_raw = pd.read_csv(input_csv, low_memory=False)\n",
    "print(f\"Loaded {len(df_raw):,} rows\")\n",
    "\n",
    "# Extract all SQL injection features\n",
    "df = extract_features(df_raw)\n",
    "print(f\"Extracted features: {df.columns.tolist()[-7:]}\")\n",
    "print(f\"Rule-based detections: {df['is_sqli_flag'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819d6cf",
   "metadata": {},
   "source": [
    "## Train Isolation Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "feature_cols = ['has_sql_keyword', 'sql_keyword_count', 'has_sql_meta',\n",
    "                'suspicious_param_pattern', 'sql_payload_length', 'sqli_count_60min_user']\n",
    "feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "\n",
    "X_raw = df[feature_cols].fillna(0).astype(float).values\n",
    "print(f\"Training with features: {feature_cols}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_raw)\n",
    "\n",
    "# Train model\n",
    "contamination = 0.02\n",
    "model = IsolationForest(contamination=contamination, random_state=42)\n",
    "model.fit(X)\n",
    "print(f\"Model trained with contamination={contamination}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dddbde",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7154c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model.predict(X)\n",
    "df['is_anomaly'] = (preds == -1).astype(int)\n",
    "df['final_alert'] = ((df['is_sqli_flag'] == 1) | (df['is_anomaly'] == 1)).astype(int)\n",
    "\n",
    "alerts = df[df['final_alert'] == 1]\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Rule-based detections: {df['is_sqli_flag'].sum():,}\")\n",
    "print(f\"ML-based detections: {df['is_anomaly'].sum():,}\")\n",
    "print(f\"Total alerts: {len(alerts):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210bac2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_save_path = '../models/sqli_detection_model.joblib'\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_cols': feature_cols,\n",
    "    'model_type': 'sqli_detection',\n",
    "    'features_module': 'src.features.sql_injection',  # For dynamic loading in pipeline\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'contamination': contamination\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39316ec",
   "metadata": {},
   "source": [
    "## Save Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save alerts\n",
    "alerts_path = '../output/sqli_alerts.csv'\n",
    "os.makedirs(os.path.dirname(alerts_path), exist_ok=True)\n",
    "alerts.to_csv(alerts_path, index=False)\n",
    "print(f\"Alerts saved to: {alerts_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
